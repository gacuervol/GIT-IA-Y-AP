{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline Audio Cetáceos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-99_mnpHTDq"
      },
      "source": [
        "# Pipeline Hola Cetáceos\n",
        "---\n",
        "### Giovanny Alejandro Cuervo Londoño\n",
        "\n",
        "En este notebook se pretende realizar el entubamiento del conjunto de datos de audios de la <a href=\"https://cis.whoi.edu/science/B/whalesounds/index.cfm\\\"> Watkins Marine Mammal Sound Database \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GCOS-H_IjgC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import re\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgnQgmOQJFXi",
        "outputId": "90c66b4f-2cf0-4993-9765-3ff66ef58d10"
      },
      "source": [
        "!python --version\n",
        "print('NumPy', np.__version__)\n",
        "print('Pandas', pd.__version__)\n",
        "print('librosa', librosa.__version__)\n",
        "print('re', re.__version__)\n",
        "print('tensorflow', tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.10\n",
            "NumPy 1.19.5\n",
            "Pandas 1.1.5\n",
            "librosa 0.8.0\n",
            "re 2.2.1\n",
            "tensorflow 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-y3i2kNJJh1"
      },
      "source": [
        "Este notebook se creó con estas versiones de módulos:\n",
        "> Python 3.7.10\n",
        "\n",
        "> NumPy 1.19.5\n",
        "\n",
        "> Pandas 1.1.5\n",
        "\n",
        "> librosa 0.8.0\n",
        "\n",
        "> re 2.2.1\n",
        "\n",
        "> tensorflow 2.4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJSFRNN3t3s_"
      },
      "source": [
        "Conectamos nuestro directorio a de audios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyD6BWYPJfbj",
        "outputId": "3583ad6e-f204-43da-f498-88ebb5501bca"
      },
      "source": [
        "#si esta trabajando en google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Cargamos los datos de un directorio local\n",
        "pathdir = '/content/drive/MyDrive/Colab Notebooks/IA y AP/Proyecto/Audios/'\n",
        "listdir = os.listdir(pathdir)\n",
        "print(f'Cantidad de audios: {len(listdir)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Cantidad de audios: 1697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LcNfKxthCU_"
      },
      "source": [
        "## Creacion del vector de Etiquetas\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYXjnQvhJjHd"
      },
      "source": [
        "#funcion para generar las etiquetas\n",
        "def etiquetas_audios(list_audios):\n",
        "  \"\"\"\n",
        "  Esta función tiene como input la lista\n",
        "  de los nombres de los audios y retorna\n",
        "  los nombres sin su numero y .mp4\n",
        "  \"\"\"\n",
        "  names = []\n",
        "  for audio in list_audios:\n",
        "    split_name = re.split(r'\\d', audio, maxsplit=2)\n",
        "    names.append(split_name[0])\n",
        "  return names"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE_e4lYoKvhW"
      },
      "source": [
        "nombre_cetace = etiquetas_audios(listdir)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaDHn_BZuBTE"
      },
      "source": [
        "## Creación de matriz de audios\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DScPUCygdg7"
      },
      "source": [
        "#convertimos los audios a una matriz shape(109620,2)\n",
        "def audio2matriz(cetaceo, filas):\n",
        "  \"\"\"\n",
        "  Esta función tiene como input el audio y \n",
        "  la cantidad de filas deseadas para retornar\n",
        "  una matriz de shape(filas, 2) donde las\n",
        "  dos columansa son amplitud y timepo\n",
        "  \"\"\"\n",
        "  y_1, sr_1 = librosa.load(pathdir+cetaceo)\n",
        "  duration = len(y_1)/sr_1\n",
        "  sr = filas/duration \n",
        "  y_1 = librosa.resample(y_1, sr_1, sr)\n",
        "  #algunas veces los decimales no alcanzan y sale con una fila mas\n",
        "  if len(y_1) == filas+1:\n",
        "    y_1 = y_1[:filas]\n",
        "  #convierte amplitudes a tiempos\n",
        "  amplitu2time = lambda y_1, sr : list(map(lambda x : x/sr,range(len(y_1))))\n",
        "  time = amplitu2time(y_1, sr)\n",
        "  #concatena amplitudes y tiempos\n",
        "  Ampli0time = lambda A, t: np.concatenate((np.array(A).reshape(-1, 1), np.array(t).reshape(-1, 1)), axis= 1)\n",
        "  Matriz = Ampli0time(y_1, time)\n",
        "  \n",
        "  return Matriz\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNrcFKbz1ZGV"
      },
      "source": [
        "## Creación del Tensor de Audios\n",
        "---\n",
        "Se busca crear matrices para cada uno de los audios con el mismo tamaño para poder apilarlos para formar un tensor de dimensiones: (1602, 109620, 2). dos columnas que representan los puntos de amplitudes y el tiempos de 109620 filas de sampleos para 1602 audios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH-lsY1i0rYr"
      },
      "source": [
        "def tupla_tensors(desde, hasta):\n",
        "  \"\"\"\n",
        "  Esta función tiene como input el idx incial \n",
        "  y el idx final de la lista de audios listdir\n",
        "  y retorna una tupla de dos tensores de tensorflow\n",
        "  del vector de nombres y la matriz de audios \n",
        "  \"\"\"\n",
        "  M = audio2matriz(listdir[desde], 109620)\n",
        "  M = M[np.newaxis, :, :]\n",
        "  nombre_cetace = etiquetas_audios(listdir[desde:hasta])\n",
        "  for audio in range(desde+1, hasta):\n",
        "    M_2 = audio2matriz(listdir[audio], 109620)\n",
        "    M_2 = M_2[np.newaxis, :, :]\n",
        "    M = np.concatenate((M, M_2), axis=0)\n",
        "  yield (tf.constant(nombre_cetace), tf.constant(M))\n",
        "        "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbCqVSB_9tuN",
        "outputId": "f1a709be-2f1b-4a45-8202-cfb0975cba06"
      },
      "source": [
        "Tensor_data = tupla_tensors(0,3)\n",
        "print(next(Tensor_data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
            "array([b'Humpback Whale', b'Humpback Whale', b'Humpback Whale'],\n",
            "      dtype=object)>, <tf.Tensor: shape=(3, 109620, 2), dtype=float64, numpy=\n",
            "array([[[ 4.49563786e-02,  0.00000000e+00],\n",
            "        [ 6.17534816e-02,  6.89634487e-05],\n",
            "        [ 5.63177690e-02,  1.37926897e-04],\n",
            "        ...,\n",
            "        [ 1.72668621e-02,  7.55956635e+00],\n",
            "        [ 2.19469201e-02,  7.55963532e+00],\n",
            "        [ 7.48272240e-03,  7.55970428e+00]],\n",
            "\n",
            "       [[ 3.68937780e-03,  0.00000000e+00],\n",
            "        [ 1.20888213e-02,  1.56908156e-04],\n",
            "        [ 1.37021476e-02,  3.13816313e-04],\n",
            "        ...,\n",
            "        [-2.36057267e-02,  1.71998014e+01],\n",
            "        [-2.23530717e-02,  1.71999583e+01],\n",
            "        [ 0.00000000e+00,  1.72001152e+01]],\n",
            "\n",
            "       [[ 2.89834309e-02,  0.00000000e+00],\n",
            "        [ 4.94505689e-02,  1.40939986e-04],\n",
            "        [ 4.60001454e-02,  2.81879972e-04],\n",
            "        ...,\n",
            "        [ 8.60219747e-02,  1.54494184e+01],\n",
            "        [ 9.03071985e-02,  1.54495594e+01],\n",
            "        [ 7.36405477e-02,  1.54497003e+01]]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duwq5BC6uPc7"
      },
      "source": [
        "Creamos nuestro de tensorflow dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLoB4cC1Kej"
      },
      "source": [
        "Tensor_data = tupla_tensors(0,5) #toma los primero 5 audios\n",
        "dataset0cetaceo = tf.data.Dataset.from_tensor_slices(next(Tensor_data))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xsFUto2ugyL",
        "outputId": "a93ccd9a-ae24-4062-c9dc-065ddf02549b"
      },
      "source": [
        "print(f'tupla: \\n{dataset0cetaceo.element_spec}') #tupla de info (etiquetas, matriz datos)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tupla: \n",
            "(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(109620, 2), dtype=tf.float64, name=None))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZiXli6PreAP",
        "outputId": "992929be-9442-4d01-96bc-57307cf0d23d"
      },
      "source": [
        "#para ver los elementos de etiquetas + matriz de datos\n",
        "print(list(dataset0cetaceo.as_numpy_iterator())[0]) \n",
        "print(list(dataset0cetaceo.as_numpy_iterator())[1])\n",
        "print(list(dataset0cetaceo.as_numpy_iterator())[2])\n",
        "print(list(dataset0cetaceo.as_numpy_iterator())[3])\n",
        "print(list(dataset0cetaceo.as_numpy_iterator())[4])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(b'Humpback Whale', array([[4.49563786e-02, 0.00000000e+00],\n",
            "       [6.17534816e-02, 6.89634487e-05],\n",
            "       [5.63177690e-02, 1.37926897e-04],\n",
            "       ...,\n",
            "       [1.72668621e-02, 7.55956635e+00],\n",
            "       [2.19469201e-02, 7.55963532e+00],\n",
            "       [7.48272240e-03, 7.55970428e+00]]))\n",
            "(b'Humpback Whale', array([[ 3.68937780e-03,  0.00000000e+00],\n",
            "       [ 1.20888213e-02,  1.56908156e-04],\n",
            "       [ 1.37021476e-02,  3.13816313e-04],\n",
            "       ...,\n",
            "       [-2.36057267e-02,  1.71998014e+01],\n",
            "       [-2.23530717e-02,  1.71999583e+01],\n",
            "       [ 0.00000000e+00,  1.72001152e+01]]))\n",
            "(b'Humpback Whale', array([[2.89834309e-02, 0.00000000e+00],\n",
            "       [4.94505689e-02, 1.40939986e-04],\n",
            "       [4.60001454e-02, 2.81879972e-04],\n",
            "       ...,\n",
            "       [8.60219747e-02, 1.54494184e+01],\n",
            "       [9.03071985e-02, 1.54495594e+01],\n",
            "       [7.36405477e-02, 1.54497003e+01]]))\n",
            "(b'Humpback Whale', array([[ 1.20717008e-03,  0.00000000e+00],\n",
            "       [ 2.84732017e-03,  1.52181045e-05],\n",
            "       [ 5.15410537e-03,  3.04362090e-05],\n",
            "       ...,\n",
            "       [-4.09625427e-05,  1.66816296e+00],\n",
            "       [ 2.80710286e-04,  1.66817818e+00],\n",
            "       [ 2.19864902e-04,  1.66819340e+00]]))\n",
            "(b'Humpback Whale', array([[4.60481038e-03, 0.00000000e+00],\n",
            "       [5.07450756e-03, 2.69957110e-04],\n",
            "       [3.16447136e-03, 5.39914220e-04],\n",
            "       ...,\n",
            "       [2.85038282e-03, 2.95918885e+01],\n",
            "       [2.24278122e-03, 2.95921585e+01],\n",
            "       [2.42189388e-03, 2.95924285e+01]]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ampP3EJrj0Y"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}