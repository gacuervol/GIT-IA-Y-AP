{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-99_mnpHTDq"
   },
   "source": [
    "# Pipeline Hola Cetáceos\n",
    "---\n",
    "### Giovanny Alejandro Cuervo Londoño\n",
    "\n",
    "En este notebook se pretende realizar el entubamiento del conjunto de datos de audios de la <a href=\"https://cis.whoi.edu/science/B/whalesounds/index.cfm\\\"> Watkins Marine Mammal Sound Database \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3GCOS-H_IjgC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgnQgmOQJFXi",
    "outputId": "90c66b4f-2cf0-4993-9765-3ff66ef58d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.8.5\n",
      "NumPy 1.19.2\n",
      "Pandas 1.1.3\n",
      "librosa 0.8.0\n",
      "re 2.2.1\n",
      "tensorflow 2.4.1\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "print('NumPy', np.__version__)\n",
    "print('Pandas', pd.__version__)\n",
    "print('librosa', librosa.__version__)\n",
    "print('re', re.__version__)\n",
    "print('tensorflow', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-y3i2kNJJh1"
   },
   "source": [
    "Este notebook se creó con estas versiones de módulos:\n",
    "> Python 3.7.10\n",
    "\n",
    "> NumPy 1.19.5\n",
    "\n",
    "> Pandas 1.1.5\n",
    "\n",
    "> librosa 0.8.0\n",
    "\n",
    "> re 2.2.1\n",
    "\n",
    "> tensorflow 2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yJSFRNN3t3s_"
   },
   "source": [
    "Conectamos nuestro directorio a de audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QyD6BWYPJfbj",
    "outputId": "3583ad6e-f204-43da-f498-88ebb5501bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de audios: 1697\n"
     ]
    }
   ],
   "source": [
    "#si esta trabajando en google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "#Cargamos los datos de un directorio local\n",
    "pathdir = '/home/mofoko/Desktop/Diplomato intel artificial/IA y AP/Proyecto/Audios/Audios/'\n",
    "listdir = os.listdir(pathdir)\n",
    "print(f'Cantidad de audios: {len(listdir)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LcNfKxthCU_"
   },
   "source": [
    "## Creacion del vector de Etiquetas\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "fYXjnQvhJjHd"
   },
   "outputs": [],
   "source": [
    "#funcion para generar las etiquetas\n",
    "def etiquetas_audios(list_audios):\n",
    "    \n",
    "  \"\"\"\n",
    "  Esta función tiene como input la lista\n",
    "  de los nombres de los audios y retorna\n",
    "  los nombres sin su numero y .mp4\n",
    "  \"\"\"\n",
    "  names = []\n",
    "  for audio in list_audios:\n",
    "    split_name = re.split(r'\\d', audio, maxsplit=2)\n",
    "    names.append(split_name[0])\n",
    "  return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gE_e4lYoKvhW"
   },
   "outputs": [],
   "source": [
    "nombre_cetace = etiquetas_audios(listdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaDHn_BZuBTE"
   },
   "source": [
    "## Creación de matriz de audios\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1DScPUCygdg7"
   },
   "outputs": [],
   "source": [
    "#convertimos los audios a una matriz shape(109620,2)\n",
    "def audio2matriz(cetaceo, filas):\n",
    "  \"\"\"\n",
    "  Esta función tiene como input el audio y \n",
    "  la cantidad de filas deseadas para retornar\n",
    "  una matriz de shape(filas, 2) donde las\n",
    "  dos columansa son amplitud y timepo\n",
    "  \"\"\"\n",
    "  y_1, sr_1 = librosa.load(pathdir+cetaceo)\n",
    "  duration = len(y_1)/sr_1\n",
    "  sr = filas/duration \n",
    "  y_1 = librosa.resample(y_1, sr_1, sr)\n",
    "  #algunas veces los decimales no alcanzan y sale con una fila mas\n",
    "  if len(y_1) == filas+1:\n",
    "    y_1 = y_1[:filas]\n",
    "  #convierte amplitudes a tiempos\n",
    "  amplitu2time = lambda y_1, sr : list(map(lambda x : x/sr,range(len(y_1))))\n",
    "  time = amplitu2time(y_1, sr)\n",
    "  #concatena amplitudes y tiempos\n",
    "  Ampli0time = lambda A, t: np.concatenate((np.array(A).reshape(-1, 1), np.array(t).reshape(-1, 1)), axis= 1)\n",
    "  Matriz = Ampli0time(y_1, time)\n",
    "  \n",
    "  return Matriz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNrcFKbz1ZGV"
   },
   "source": [
    "## Creación del Tensor de Audios\n",
    "---\n",
    "Se busca crear matrices para cada uno de los audios con el mismo tamaño para poder apilarlos para formar un tensor de dimensiones: (1602, 109620, 2). dos columnas que representan los puntos de amplitudes y el tiempos de 109620 filas de sampleos para 1602 audios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definimos un generador\n",
    "def tupla(n):\n",
    "  \"\"\"\n",
    "  Esta función declara un generador que tiene como input n\n",
    "  el numero de audios de la lista listdir a generar \n",
    "  retornando una tupla de dos: nombre y la matriz del audio \n",
    "  \"\"\"\n",
    "  listdir_n = listdir[:n]\n",
    "  list_names = etiquetas_audios(listdir_n)\n",
    "  for name, path_name in zip(list_names, listdir_n):\n",
    "    M = audio2matriz(path_name, 109620)\n",
    "    yield name, M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duwq5BC6uPc7"
   },
   "source": [
    "Creamos nuestro de tensorflow dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_counter = tf.data.Dataset.from_generator(tupla, args=[3], output_types=(tf.string, tf.float64), output_shapes=((), (109620, 2)))\n",
    "#args=[3] es el argumento n del generador tupla(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Long-Finned Pilot Whale'>, <tf.Tensor: shape=(109620, 2), dtype=float64, numpy=\n",
      "array([[ 2.66532600e-03,  0.00000000e+00],\n",
      "       [ 3.46068270e-03,  9.73968618e-06],\n",
      "       [ 4.04257560e-03,  1.94793724e-05],\n",
      "       ...,\n",
      "       [-1.12582243e-03,  1.06763518e+00],\n",
      "       [-1.19674951e-03,  1.06764492e+00],\n",
      "       [ 0.00000000e+00,  1.06765466e+00]])>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'False Killer Whale'>, <tf.Tensor: shape=(109620, 2), dtype=float64, numpy=\n",
      "array([[2.74948007e-03, 0.00000000e+00],\n",
      "       [3.08781373e-03, 6.52842783e-06],\n",
      "       [3.29862838e-03, 1.30568557e-05],\n",
      "       ...,\n",
      "       [4.68908547e-04, 7.15626673e-01],\n",
      "       [3.91415844e-04, 7.15633202e-01],\n",
      "       [2.61516601e-04, 7.15639730e-01]])>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'Bowhead Whale'>, <tf.Tensor: shape=(109620, 2), dtype=float64, numpy=\n",
      "array([[-9.10087526e-02,  0.00000000e+00],\n",
      "       [-1.84698969e-01,  4.13245758e-04],\n",
      "       [-7.42307380e-02,  8.26491516e-04],\n",
      "       ...,\n",
      "       [-1.74012348e-01,  4.52987603e+01],\n",
      "       [-1.99839503e-01,  4.52991735e+01],\n",
      "       [-1.29780456e-01,  4.52995868e+01]])>)\n"
     ]
    }
   ],
   "source": [
    "it = iter(ds_counter)\n",
    "print(next(it)) #1er slice\n",
    "print(next(it)) #2do slice\n",
    "print(next(it)) #3er slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pipeline Audio Cetáceos.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
